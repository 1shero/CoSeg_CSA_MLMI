{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pip\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.1.1\n",
      "    Uninstalling pip-20.1.1:\n",
      "      Successfully uninstalled pip-20.1.1\n",
      "Successfully installed pip-21.0.1\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting wrapt\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting enum34\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/63/f6/ccb1c83687756aeabbf3ca0f213508fcfb03883ff200d201b3a4c60cedcc/enum34-1.1.10-py3-none-any.whl (11 kB)\n",
      "Collecting simplejson\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting netaddr\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ff/cd/9cdfea8fc45c56680b798db6a55fa60a22e2d3d3ccf54fc729d083b50ce4/netaddr-0.8.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 23.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/4e/ca/0456249eead852a957d306feb0cce454b823cbc3bea7821971febfa45f99/setuptools-53.1.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 17.7 MB/s eta 0:00:01 | 8.3 MB 17.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b6/c0/442d9d87e0da00bf856ef6dd4916f84a2d710b5f1a367d42d7f3c4e99a6c/Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 18.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/82/70/7bf5f275a738629a7252c30c8461502d3658a75363db9f4f88ddbeb9eeac/importlib_resources-5.1.0-py3-none-any.whl (24 kB)\n",
      "Collecting zipp>=0.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=68112 sha256=ae1dd7981a882a9a516d7aa8134758dcd0fe783e8bbb602134ef781fb8216455\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/2e/15/15/1d0000a58c51f3e43a85ab35ff995e48ee66f5458b146c5d03\n",
      "Successfully built wrapt\n",
      "Installing collected packages: zipp, pillow, numpy, importlib-resources, wrapt, simplejson, setuptools, netaddr, imageio, enum34\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.1.6 requires pandas>=0.24.2, but you have pandas 0.22.0 which is incompatible.\n",
      "modelarts 1.1.6 requires urllib3==1.21.1, but you have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "Successfully installed enum34-1.1.10 imageio-2.9.0 importlib-resources-5.1.0 netaddr-0.8.0 numpy-1.19.5 pillow-8.1.0 setuptools-53.1.0 simplejson-3.17.2 wrapt-1.12.1 zipp-3.4.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting matplotlib==2.2.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.6 MB 18.5 MB/s eta 0:00:01             | 7.4 MB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (2.6.1)\n",
      "Requirement already satisfied: six>=1.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (1.14.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 17.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (2017.3)\n",
      "Installing collected packages: kiwisolver, matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 2.1.2\n",
      "    Uninstalling matplotlib-2.1.2:\n",
      "      Successfully uninstalled matplotlib-2.1.2\n",
      "Successfully installed kiwisolver-1.3.1 matplotlib-2.2.3\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (3.12)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from h5py) (1.19.5)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from h5py) (1.14.0)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scikit-image in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (0.13.1)\n",
      "Collecting scikit-image\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 18.0 MB/s eta 0:00:01�██████████▍             | 7.2 MB 18.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (2.2.3)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/42/6b/93a8ee61c6fbe20fa9c17928bd3b80484902b7fd454cecaffba42f5052cb/tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 18.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (2.1)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/59/bb/d2b85265ec9fa3c1922210c9393d4cdf7075cc87cce6fe671d7455f80fbc/PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 22.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (8.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: pytz in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2017.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.6.1)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.2.1)\n",
      "Installing collected packages: tifffile, PyWavelets, scikit-image\n",
      "  Attempting uninstall: PyWavelets\n",
      "    Found existing installation: PyWavelets 0.5.2\n",
      "    Uninstalling PyWavelets-0.5.2:\n",
      "      Successfully uninstalled PyWavelets-0.5.2\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.13.1\n",
      "    Uninstalling scikit-image-0.13.1:\n",
      "      Successfully uninstalled scikit-image-0.13.1\n",
      "Successfully installed PyWavelets-1.1.1 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "Found existing installation: numpy 1.19.5\n",
      "Uninstalling numpy-1.19.5:\n",
      "  Successfully uninstalled numpy-1.19.5\n",
      "Found existing installation: numpy 1.18.4\n",
      "Uninstalling numpy-1.18.4:\n",
      "  Successfully uninstalled numpy-1.18.4\n",
      "Found existing installation: numpy 1.20.1\n",
      "Uninstalling numpy-1.20.1:\n",
      "  Successfully uninstalled numpy-1.20.1\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting numpy==1.18.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 4.9 MB/s eta 0:00:01MB/s eta 0:00:02| 18.2 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.1.6 requires pandas>=0.24.2, but you have pandas 0.22.0 which is incompatible.\n",
      "modelarts 1.1.6 requires urllib3==1.21.1, but you have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.18.4\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pyarrow==0.16.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/00/d2/695bab1e1e7a4554b6dbd287d55cca096214bd441037058a432afd724bb1/pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.1 MB 17.0 MB/s eta 0:00:01��█████████████████▏            | 37.7 MB 17.0 MB/s eta 0:00:02B 17.0 MB/s eta 0:00:02 | 51.8 MB 17.0 MB/s eta 0:00:01�████████████████████████████  | 59.2 MB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pyarrow==0.16.0) (1.18.4)\n",
      "Requirement already satisfied: six>=1.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pyarrow==0.16.0) (1.14.0)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-0.16.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting protobuf==3.12.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/35/6c/d1cf8521f94b332851cf95dbf679a72271ba85b367e2283b9f5f6cdf98bc/protobuf-3.12.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 18.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from protobuf==3.12.0) (53.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from protobuf==3.12.0) (1.14.0)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.1\n",
      "    Uninstalling protobuf-3.12.1:\n",
      "      Successfully uninstalled protobuf-3.12.1\n",
      "Successfully installed protobuf-3.12.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting SimpleITK\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/cc/85/6a7ce61f07cdaca722dd64f028b5678fb0a9e1bf66f534c2f8dd2eb78490/SimpleITK-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (47.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.4 MB 22.6 MB/s eta 0:00:01               | 14.4 MB 22.6 MB/s eta 0:00:02███▉                 | 22.0 MB 22.6 MB/s eta 0:00:02   | 29.4 MB 22.6 MB/s eta 0:00:01██████▋       | 36.5 MB 22.6 MB/s eta 0:00:01    |█████████████████████████████▍  | 43.5 MB 22.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: SimpleITK\n",
      "Successfully installed SimpleITK-2.0.2\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scipy in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scipy) (1.18.4)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pydot\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ea/76/75b1bb82e9bad3e3d656556eaa353d8cd17c4254393b08ec9786ac8ed273/pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pydot) (2.2.0)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (0.19.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 17.8 MB/s eta 0:00:01██▏                      | 6.4 MB 17.8 MB/s eta 0:00:01�████████▋           | 14.3 MB 17.8 MB/s eta 0:00:01█▏| 21.7 MB 17.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-learn) (1.4.1)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-learn) (1.18.4)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.1 threadpoolctl-2.1.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting keras_unet\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b0/f6/783d69bd0c5b250abcf0d0f187ce7b3e2cc2332315068d2fd14662b0471e/keras_unet-0.1.2-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: keras-unet\n",
      "Successfully installed keras-unet-0.1.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install -U --ignore-installed wrapt enum34 simplejson netaddr imageio setuptools\n",
    "\n",
    "# !pip install matplotlib==2.2.3\n",
    "# !pip install pyyaml h5py\n",
    "\n",
    "# !pip install --upgrade scikit-image\n",
    "\n",
    "# !pip uninstall numpy --yes\n",
    "# !pip uninstall numpy --yes\n",
    "# !pip uninstall numpy --yes\n",
    "# !pip install numpy==1.18.4\n",
    "\n",
    "# !pip install pyarrow==0.16.0\n",
    "# !pip install protobuf==3.12.0\n",
    "\n",
    "# !pip install SimpleITK\n",
    "# !pip install scipy\n",
    "# !pip install pydot\n",
    "\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install keras_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.1.0\n",
      "Uninstalling tensorflow-2.1.0:\n",
      "  Successfully uninstalled tensorflow-2.1.0\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting tensorflow-gpu==2.3.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0f/11/763f55d3d15efd778ef24453f126e6c33635680e5a2bb346da3fab5997cb/tensorflow_gpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |███████████████████████████▋    | 275.9 MB 215.5 MB/s eta 0:00:01                   | 14.0 MB 5.2 MB/s eta 0:01:00                      | 17.7 MB 5.2 MB/s eta 0:00:5927.6 MB 5.2 MB/s eta 0:00:57                    | 42.8 MB 5.2 MB/s eta 0:00:54                    | 50.6 MB 5.2 MB/s eta 0:00:53 eta 0:00:51██▋                         | 66.7 MB 5.2 MB/s eta 0:00:49                  | 73.5 MB 5.2 MB/s eta 0:00:48 MB 5.2 MB/s eta 0:00:47B 243.8 MB/s eta 0:00:01��███▋                      | 95.8 MB 243.8 MB/s eta 0:00:01                  | 102.3 MB 243.8 MB/s eta 0:00:01          | 110.1 MB 243.8 MB/s eta 0:00:01��█▌                   | 125.2 MB 243.8 MB/s eta 0:00:01██▏                  | 131.7 MB 243.8 MB/s eta 0:00:01██▉                  | 138.3 MB 243.8 MB/s eta 0:00:01██████████████▌                 | 144.9 MB 243.8 MB/s eta 0:00:01███████████████                 | 151.3 MB 243.8 MB/s eta 0:00:01| 157.2 MB 243.8 MB/s eta 0:00:01█████▍               | 164.1 MB 243.8 MB/s eta 0:00:01��███████               | 170.5 MB 243.8 MB/s eta 0:00:01[K     |█████████████████▊              | 177.5 MB 243.8 MB/s eta 0:00:01��█████████████████▍             | 184.5 MB 243.8 MB/s eta 0:00:01�███████▏            | 191.6 MB 243.8 MB/s eta 0:00:01MB 243.8 MB/s eta 0:00:01 215.5 MB/s eta 0:00:01 215.5 MB/s eta 0:00:01��█▋         | 226.8 MB 215.5 MB/s eta 0:00:01█████▎        | 232.8 MB 215.5 MB/s eta 0:00:01��████████████████        | 239.5 MB 215.5 MB/s eta 0:00:01ta 0:00:01 257.6 MB 215.5 MB/s eta 0:00:01�██████▎     | 263.5 MB 215.5 MB/s eta 0:00:01�██████▊     | 267.8 MB 215.5 MB/s eta 0:00:01��██████████████████▏    | 271.6 MB 215.5 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.18.4)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (0.30.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 18.4 MB/s eta 0:00:01▋        | 7.8 MB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (3.2.1)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 18.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.29.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (0.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (3.12.0)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow-gpu==2.3.0) (53.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.15.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/1a/c1/499e600ba0c618b451cd9c425ae1c177249940a2086316552fee7d86c954/tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 19.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.22)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2018.1.18)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4.0)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorflow-estimator, tensorboard, h5py, gast, astunparse, tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.7.1\n",
      "    Uninstalling h5py-2.7.1:\n",
      "      Successfully uninstalled h5py-2.7.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "Successfully installed astunparse-1.6.3 gast-0.3.3 h5py-2.10.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting keras==2.4.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (1.18.4)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from h5py->keras==2.4.3) (1.14.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 16.5 MB/s eta 0:00:01�██████████████████████████  | 9.5 MB 16.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pandas==0.24.2) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pandas==0.24.2) (2017.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pandas==0.24.2) (1.18.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.24.2) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.1.6 requires urllib3==1.21.1, but you have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "Successfully installed pandas-0.24.2\n",
      "Found existing installation: urllib3 1.22\n",
      "Uninstalling urllib3-1.22:\n",
      "  Successfully uninstalled urllib3-1.22\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: urllib3==1.21.1 in /home/ma-user/modelarts-sdk (1.21.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall tensorflow --yes\n",
    "# !pip uninstall tensorflow --yes\n",
    "\n",
    "# !pip uninstall tensorflow-gpu --yes\n",
    "# !pip uninstall tensorflow-gpu --yes\n",
    "\n",
    "# !pip uninstall keras --yes\n",
    "# !pip uninstall keras --yes\n",
    "\n",
    "# !pip install tensorflow-gpu==2.3.0  # 2.3.0\n",
    "# !pip install --upgrade keras==2.4.3 # 2.3.1\n",
    "\n",
    "# !pip install pandas==0.24.2\n",
    "# !pip uninstall urllib3 --yes\n",
    "# !pip install urllib3==1.21.1  # 1.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding3D, BatchNormalization, Flatten, Conv3D, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D, Concatenate\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from load_preprocess_util import *\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filem:\t ('VertSeg_train/masks_222_t', [], ['mask004.nii', 'mask006.nii', 'mask009.nii', 'mask005.nii', 'mask008.nii', 'mask001.nii', 'mask002.nii', 'mask012.nii', 'mask010.nii', 'mask011.nii', 'mask007.nii', 'mask003.nii'])\n",
      "files2:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii']\n",
      "files1:\t ['image001.nii', 'image002.nii', 'image003.nii', 'image004.nii', 'image005.nii', 'image006.nii', 'image007.nii', 'image008.nii', 'image009.nii', 'image010.nii', 'image011.nii', 'image012.nii']\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 0\n",
      "mask001.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask001.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "0\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 1\n",
      "mask002.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask002.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "1\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 2\n",
      "mask003.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask003.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "2\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 3\n",
      "mask004.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask004.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "3\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 4\n",
      "mask005.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask005.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "4\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 5\n",
      "mask006.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask006.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "5\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 6\n",
      "mask007.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask007.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "6\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 7\n",
      "mask008.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask008.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "7\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 8\n",
      "mask009.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask009.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "8\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 9\n",
      "mask010.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask010.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "9\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 10\n",
      "mask011.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask011.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "10\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii'] \t 11\n",
      "mask012.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask012.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "11\n",
      "filem:\t ('VertSeg_train/masks_222_t_v', ['.ipynb_checkpoints'], ['mask014.nii', 'mask015.nii', 'mask013.nii'])\n",
      "filem:\t ('VertSeg_train/masks_222_t_v/.ipynb_checkpoints', [], [])\n",
      "files2:\t ['mask013.nii', 'mask014.nii', 'mask015.nii']\n",
      "files1:\t ['image013.nii', 'image014.nii', 'image015.nii']\n",
      "files22:\t ['mask013.nii', 'mask014.nii', 'mask015.nii'] \t 0\n",
      "mask013.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t_v/mask013.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "0\n",
      "files22:\t ['mask013.nii', 'mask014.nii', 'mask015.nii'] \t 1\n",
      "mask014.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t_v/mask014.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "1\n",
      "files22:\t ['mask013.nii', 'mask014.nii', 'mask015.nii'] \t 2\n",
      "mask015.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t_v/mask015.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "2\n",
      "files1:\t []\n"
     ]
    }
   ],
   "source": [
    "# load CT data\n",
    "import random\n",
    "\n",
    "data_dir1 = 'VertSeg_train/images_222_t'\n",
    "mask_dir1 = 'VertSeg_train/masks_222_t'\n",
    "\n",
    "data_dir1_v = 'VertSeg_train/images_222_t_v'\n",
    "mask_dir1_v = 'VertSeg_train/masks_222_t_v'\n",
    "\n",
    "\n",
    "data1, mask1 = load_data(data_dir1, mask_dir1)\n",
    "data1_v, mask1_v = load_data(data_dir1_v, mask_dir1_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mask1.nii', 'mask2.nii', 'mask4.nii', 'mask5.nii']\n",
      "['image1.nii', 'image2.nii', 'image4.nii', 'image5.nii']\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "0\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "1\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "2\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "3\n",
      "['mask3.nii']\n",
      "['image3.nii']\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# load MR data\n",
    "import random\n",
    "\n",
    "data_dir2 = 'MRI/images'\n",
    "mask_dir2 = 'MRI/masks'\n",
    "\n",
    "data_dir2_v = 'MRI/images_v'\n",
    "mask_dir2_v = 'MRI/masks_v'\n",
    "\n",
    "data1, mask1 = load_MR_data(data_dir2, mask_dir2)\n",
    "data1_v, mask1_v = load_MR_data(data_dir2_v, mask_dir2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv3D(F1, (1, 1, 1), strides = (s,s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F2, kernel_size = (f, f, f), strides = (1,1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F3, kernel_size = (1, 1, 1), strides = (1,1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv3D(filters = F3, kernel_size = (1, 1 ,1), strides = (s,s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 4, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv3D(filters = F1, kernel_size = (1, 1, 1), strides = (1,1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F2, kernel_size = (f, f,f), strides = (1,1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F3, kernel_size = (1, 1,1), strides = (1,1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Utilities for DeepLab\n",
    "Lei Mao\n",
    "Department of Computer Science\n",
    "University of Chicago\n",
    "dukeleimao@gmail.com\n",
    "'''\n",
    "\n",
    "def atrous_spatial_pyramid_pooling(inputs, filters=256, regularizer=None):\n",
    "    '''\n",
    "    Atrous Spatial Pyramid Pooling (ASPP) Block\n",
    "    '''\n",
    "    print('input: ',inputs.shape)\n",
    "    pool_height = inputs.shape[1]\n",
    "    pool_width = inputs.shape[2]\n",
    "    pool_depth = inputs.shape[3]\n",
    "\n",
    "    resize_height = pool_height\n",
    "    resize_width = pool_width\n",
    "    resize_depth = pool_depth\n",
    "\n",
    "    # Atrous Spatial Pyramid Pooling\n",
    "    # Atrous 1x1\n",
    "    aspp1x1 = Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer, name='aspp1x1')(inputs)\n",
    "    # Atrous 3x3, rate = 6\n",
    "    aspp3x3_1 = Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same', dilation_rate=(6, 6, 6), kernel_regularizer=regularizer, name='aspp3x3_1')(inputs)\n",
    "    # Atrous 3x3, rate = 12\n",
    "    aspp3x3_2 = Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same', dilation_rate=(12, 12, 12), kernel_regularizer=regularizer, name='aspp3x3_2')(inputs)\n",
    "    # Atrous 3x3, rate = 18\n",
    "    aspp3x3_3 = Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same', dilation_rate=(18, 18, 18), kernel_regularizer=regularizer, name='aspp3x3_3')(inputs)\n",
    "\n",
    "    # Image Level Pooling\n",
    "    image_feature = tf.reduce_mean(inputs, [1, 2, 3], keepdims=True)\n",
    "    image_feature = Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same')(image_feature)\n",
    "    image_feature = keras.layers.UpSampling3D(size=(resize_height, resize_width, resize_depth))(image_feature)\n",
    "    \n",
    "    # Merge Poolings\n",
    "    print(aspp1x1.shape, aspp3x3_1.shape, aspp3x3_2.shape, aspp3x3_3.shape, image_feature.shape)\n",
    "    outputs = tf.concat(values=[aspp1x1, aspp3x3_1, aspp3x3_2, aspp3x3_3, image_feature], axis=4, name='aspp_pools')\n",
    "    \n",
    "    outputs = Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer, name='aspp_outputs')(outputs)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(160, 160, 160, 2),regularizer=None):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding3D((3, 3, 3))(X_input)\n",
    "\n",
    "    X = Conv3D(64, (7, 7,7), strides=(2, 2,2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=4, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)    \n",
    "    X = ZeroPadding3D((1, 1, 1))(X)\n",
    "    X = MaxPooling3D((3, 3,3), strides=(2, 2,2))(X)\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    low_res_feature = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    X = convolutional_block(low_res_feature, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 1)#key\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    pools = atrous_spatial_pyramid_pooling(inputs=X, filters=256)\n",
    "    \n",
    "    X = keras.layers.UpSampling3D(size=4)(pools)\n",
    "    \n",
    "    low_res_feature = Conv3D(filters=48, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer)(low_res_feature)\n",
    "\n",
    "    high_low_res = Concatenate(axis=-1)([X, low_res_feature])\n",
    "    \n",
    "    X = Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(high_low_res)\n",
    "    X = BatchNormalization(axis = 4)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    \n",
    "    X = Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(X)\n",
    "    X = BatchNormalization(axis = 4)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    \n",
    "    X = keras.layers.UpSampling3D(size=2)(X)\n",
    "    X = Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "\n",
    "    X = keras.layers.UpSampling3D(size=2)(X)\n",
    "    X = Conv3D(filters=1, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer)(X)\n",
    "    out = Activation('sigmoid')(X)\n",
    "    model = Model(inputs = X_input, outputs = out, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  (None, 2, 16, 16, 2048)\n",
      "(None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256)\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model = ResNet50(input_shape=(32, 256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 256, 256 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d (ZeroPadding3D)  (None, 38, 262, 262, 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv3D)                  (None, 16, 128, 128, 22016       zero_padding3d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 128, 128, 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 128, 128, 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPadding3D (None, 18, 130, 130, 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 8, 64, 64, 64 0           zero_padding3d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv3D)         (None, 8, 64, 64, 64 4160        max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 8, 64, 64, 64 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 64, 64, 64 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv3D)         (None, 8, 64, 64, 64 110656      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 8, 64, 64, 64 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 64, 64, 64 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv3D)         (None, 8, 64, 64, 25 16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv3D)          (None, 8, 64, 64, 25 16640       max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 8, 64, 64, 25 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 8, 64, 64, 25 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 64, 64, 25 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 64, 64, 25 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv3D)         (None, 8, 64, 64, 64 16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 8, 64, 64, 64 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 64, 64, 64 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv3D)         (None, 8, 64, 64, 64 110656      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 8, 64, 64, 64 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 64, 64, 64 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv3D)         (None, 8, 64, 64, 25 16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 8, 64, 64, 25 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 64, 64, 25 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 64, 64, 25 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv3D)         (None, 8, 64, 64, 64 16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 8, 64, 64, 64 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 64, 64, 64 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv3D)         (None, 8, 64, 64, 64 110656      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 8, 64, 64, 64 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 64, 64, 64 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv3D)         (None, 8, 64, 64, 25 16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 8, 64, 64, 25 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 64, 64, 25 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 64, 64, 25 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv3D)         (None, 4, 32, 32, 12 32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 4, 32, 32, 12 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 32, 32, 12 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv3D)         (None, 4, 32, 32, 12 442496      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 32, 32, 12 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 32, 32, 12 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv3D)         (None, 4, 32, 32, 51 66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv3D)          (None, 4, 32, 32, 51 131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 32, 32, 51 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 32, 32, 51 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 32, 32, 51 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 32, 32, 51 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv3D)         (None, 4, 32, 32, 12 65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 32, 32, 12 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 32, 32, 12 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv3D)         (None, 4, 32, 32, 12 442496      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 32, 32, 12 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 32, 32, 12 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv3D)         (None, 4, 32, 32, 51 66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 32, 32, 51 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 32, 32, 51 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 32, 32, 51 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv3D)         (None, 4, 32, 32, 12 65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 32, 32, 12 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 32, 32, 12 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv3D)         (None, 4, 32, 32, 12 442496      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 32, 32, 12 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 32, 32, 12 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv3D)         (None, 4, 32, 32, 51 66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 32, 32, 51 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 32, 32, 51 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 32, 32, 51 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv3D)         (None, 4, 32, 32, 12 65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 32, 32, 12 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 32, 32, 12 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv3D)         (None, 4, 32, 32, 12 442496      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 32, 32, 12 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 32, 32, 12 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv3D)         (None, 4, 32, 32, 51 66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 32, 32, 51 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 32, 32, 51 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 32, 32, 51 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv3D)         (None, 2, 16, 16, 25 131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 2, 16, 16, 25 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 16, 16, 25 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv3D)         (None, 2, 16, 16, 25 1769728     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 16, 16, 25 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 16, 16, 25 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv3D)         (None, 2, 16, 16, 10 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv3D)          (None, 2, 16, 16, 10 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 16, 16, 10 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 16, 16, 10 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 16, 16, 10 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 16, 16, 10 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv3D)         (None, 2, 16, 16, 25 262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 16, 16, 25 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 16, 16, 25 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv3D)         (None, 2, 16, 16, 25 1769728     activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 16, 16, 25 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 16, 16, 25 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv3D)         (None, 2, 16, 16, 10 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 16, 16, 10 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 16, 16, 10 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 16, 16, 10 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv3D)         (None, 2, 16, 16, 25 262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 16, 16, 25 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 16, 16, 25 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv3D)         (None, 2, 16, 16, 25 1769728     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 16, 16, 25 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 16, 16, 25 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv3D)         (None, 2, 16, 16, 10 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 16, 16, 10 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 16, 16, 10 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 16, 16, 10 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv3D)         (None, 2, 16, 16, 25 262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 16, 16, 25 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 16, 16, 25 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv3D)         (None, 2, 16, 16, 25 1769728     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 16, 16, 25 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 16, 16, 25 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv3D)         (None, 2, 16, 16, 10 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 16, 16, 10 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 16, 16, 10 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 16, 16, 10 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv3D)         (None, 2, 16, 16, 25 262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 16, 16, 25 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 16, 16, 25 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv3D)         (None, 2, 16, 16, 25 1769728     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 16, 16, 25 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 16, 16, 25 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv3D)         (None, 2, 16, 16, 10 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 16, 16, 10 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 16, 16, 10 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 16, 16, 10 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv3D)         (None, 2, 16, 16, 25 262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 16, 16, 25 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 16, 16, 25 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv3D)         (None, 2, 16, 16, 25 1769728     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 16, 16, 25 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 2, 16, 16, 25 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv3D)         (None, 2, 16, 16, 10 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 16, 16, 10 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 16, 16, 10 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 2, 16, 16, 10 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv3D)         (None, 2, 16, 16, 51 524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 16, 16, 51 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 16, 16, 51 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv3D)         (None, 2, 16, 16, 51 7078400     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 16, 16, 51 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 16, 16, 51 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv3D)         (None, 2, 16, 16, 20 1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv3D)          (None, 2, 16, 16, 20 2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 16, 16, 20 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 16, 16, 20 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2, 16, 16, 20 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 16, 16, 20 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv3D)         (None, 2, 16, 16, 51 1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 16, 16, 51 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 16, 16, 51 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv3D)         (None, 2, 16, 16, 51 7078400     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 16, 16, 51 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 16, 16, 51 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv3D)         (None, 2, 16, 16, 20 1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 16, 16, 20 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 16, 16, 20 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 16, 16, 20 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv3D)         (None, 2, 16, 16, 51 1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 16, 16, 51 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 16, 16, 51 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv3D)         (None, 2, 16, 16, 51 7078400     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 16, 16, 51 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 16, 16, 51 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv3D)         (None, 2, 16, 16, 20 1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 16, 16, 20 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 16, 16, 20 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 16, 16, 20 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 1, 1, 1, 204 0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 1, 1, 1, 256) 524544      tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp1x1 (Conv3D)                (None, 2, 16, 16, 25 524544      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp3x3_1 (Conv3D)              (None, 2, 16, 16, 25 14156032    activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp3x3_2 (Conv3D)              (None, 2, 16, 16, 25 14156032    activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp3x3_3 (Conv3D)              (None, 2, 16, 16, 25 14156032    activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 2, 16, 16, 25 0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_aspp_pools (TensorF [(None, 2, 16, 16, 1 0           aspp1x1[0][0]                    \n",
      "                                                                 aspp3x3_1[0][0]                  \n",
      "                                                                 aspp3x3_2[0][0]                  \n",
      "                                                                 aspp3x3_3[0][0]                  \n",
      "                                                                 up_sampling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp_outputs (Conv3D)           (None, 2, 16, 16, 25 327936      tf_op_layer_aspp_pools[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 8, 64, 64, 25 0           aspp_outputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 8, 64, 64, 48 12336       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 64, 64, 30 0           up_sampling3d_1[0][0]            \n",
      "                                                                 conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 8, 64, 64, 25 2101504     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 64, 64, 25 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 8, 64, 64, 25 1769728     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 64, 64, 25 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 32, 256, 256, 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 32, 256, 256, 257         up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 32, 256, 256, 0           conv3d_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 93,963,697\n",
      "Trainable params: 93,910,577\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "from time import strftime, gmtime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
    "checkpoint_path = \"3dres_aspp_MR.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = [ModelCheckpoint(filepath=checkpoint_path, verbose=1, monitor='val_precision', save_best_only=True, mode='max')\n",
    "               CSVLogger(\"./csv/model_history_log_{}.csv\".format(strftime(\"%Y_%b_%d, %H+8:%M:%S\", gmtime())), append=True),\n",
    "              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[keras.metrics.Precision(),keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3262 - precision: 0.5370 - binary_accuracy: 0.8764\n",
      "Epoch 00001: val_precision improved from -inf to 0.47576, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 233s 1s/step - loss: 0.3262 - precision: 0.5370 - binary_accuracy: 0.8764 - val_loss: 0.3235 - val_precision: 0.4758 - val_binary_accuracy: 0.8284\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2672 - precision: 0.5629 - binary_accuracy: 0.8813\n",
      "Epoch 00002: val_precision improved from 0.47576 to 0.49518, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 246s 1s/step - loss: 0.2672 - precision: 0.5629 - binary_accuracy: 0.8813 - val_loss: 0.3029 - val_precision: 0.4952 - val_binary_accuracy: 0.8385\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2339 - precision: 0.5862 - binary_accuracy: 0.8905\n",
      "Epoch 00003: val_precision improved from 0.49518 to 0.63174, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 246s 1s/step - loss: 0.2339 - precision: 0.5862 - binary_accuracy: 0.8905 - val_loss: 0.2871 - val_precision: 0.6317 - val_binary_accuracy: 0.8854\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2145 - precision: 0.6225 - binary_accuracy: 0.9003\n",
      "Epoch 00004: val_precision did not improve from 0.63174\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.2145 - precision: 0.6225 - binary_accuracy: 0.9003 - val_loss: 0.2561 - val_precision: 0.6073 - val_binary_accuracy: 0.8797\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1999 - precision: 0.6461 - binary_accuracy: 0.9078\n",
      "Epoch 00005: val_precision did not improve from 0.63174\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1999 - precision: 0.6461 - binary_accuracy: 0.9078 - val_loss: 0.2439 - val_precision: 0.6085 - val_binary_accuracy: 0.8836\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1943 - precision: 0.6487 - binary_accuracy: 0.9093\n",
      "Epoch 00006: val_precision did not improve from 0.63174\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1943 - precision: 0.6487 - binary_accuracy: 0.9093 - val_loss: 0.2717 - val_precision: 0.6242 - val_binary_accuracy: 0.8852\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1838 - precision: 0.6617 - binary_accuracy: 0.9142\n",
      "Epoch 00007: val_precision did not improve from 0.63174\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1838 - precision: 0.6617 - binary_accuracy: 0.9142 - val_loss: 0.2489 - val_precision: 0.6187 - val_binary_accuracy: 0.8839\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1871 - precision: 0.6604 - binary_accuracy: 0.9130\n",
      "Epoch 00008: val_precision improved from 0.63174 to 0.67488, saving model to 3dres_aspp_MR.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1871 - precision: 0.6604 - binary_accuracy: 0.9130 - val_loss: 0.2710 - val_precision: 0.6749 - val_binary_accuracy: 0.8843\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1722 - precision: 0.6820 - binary_accuracy: 0.9200\n",
      "Epoch 00009: val_precision did not improve from 0.67488\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1722 - precision: 0.6820 - binary_accuracy: 0.9200 - val_loss: 0.2677 - val_precision: 0.6415 - val_binary_accuracy: 0.8868\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1663 - precision: 0.6930 - binary_accuracy: 0.9226\n",
      "Epoch 00010: val_precision did not improve from 0.67488\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1663 - precision: 0.6930 - binary_accuracy: 0.9226 - val_loss: 0.2607 - val_precision: 0.6420 - val_binary_accuracy: 0.8893\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1599 - precision: 0.7105 - binary_accuracy: 0.9249\n",
      "Epoch 00011: val_precision did not improve from 0.67488\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1599 - precision: 0.7105 - binary_accuracy: 0.9249 - val_loss: 0.2587 - val_precision: 0.6430 - val_binary_accuracy: 0.8914\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1523 - precision: 0.7383 - binary_accuracy: 0.9287\n",
      "Epoch 00012: val_precision improved from 0.67488 to 0.70077, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1523 - precision: 0.7383 - binary_accuracy: 0.9287 - val_loss: 0.2450 - val_precision: 0.7008 - val_binary_accuracy: 0.9011\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1516 - precision: 0.7452 - binary_accuracy: 0.9294\n",
      "Epoch 00013: val_precision improved from 0.70077 to 0.71813, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 244s 1s/step - loss: 0.1516 - precision: 0.7452 - binary_accuracy: 0.9294 - val_loss: 0.2435 - val_precision: 0.7181 - val_binary_accuracy: 0.9037\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1508 - precision: 0.7512 - binary_accuracy: 0.9301\n",
      "Epoch 00014: val_precision did not improve from 0.71813\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1508 - precision: 0.7512 - binary_accuracy: 0.9301 - val_loss: 0.2447 - val_precision: 0.7094 - val_binary_accuracy: 0.9027\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1495 - precision: 0.7549 - binary_accuracy: 0.9311\n",
      "Epoch 00015: val_precision improved from 0.71813 to 0.73224, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1495 - precision: 0.7549 - binary_accuracy: 0.9311 - val_loss: 0.2423 - val_precision: 0.7322 - val_binary_accuracy: 0.9060\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1493 - precision: 0.7617 - binary_accuracy: 0.9316\n",
      "Epoch 00016: val_precision improved from 0.73224 to 0.74023, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 244s 1s/step - loss: 0.1493 - precision: 0.7617 - binary_accuracy: 0.9316 - val_loss: 0.2405 - val_precision: 0.7402 - val_binary_accuracy: 0.9072\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1483 - precision: 0.7691 - binary_accuracy: 0.9321\n",
      "Epoch 00017: val_precision did not improve from 0.74023\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1483 - precision: 0.7691 - binary_accuracy: 0.9321 - val_loss: 0.2431 - val_precision: 0.7362 - val_binary_accuracy: 0.9066\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1475 - precision: 0.7747 - binary_accuracy: 0.9330\n",
      "Epoch 00018: val_precision improved from 0.74023 to 0.75525, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1475 - precision: 0.7747 - binary_accuracy: 0.9330 - val_loss: 0.2423 - val_precision: 0.7553 - val_binary_accuracy: 0.9085\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1481 - precision: 0.7812 - binary_accuracy: 0.9331\n",
      "Epoch 00019: val_precision did not improve from 0.75525\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1481 - precision: 0.7812 - binary_accuracy: 0.9331 - val_loss: 0.2439 - val_precision: 0.7546 - val_binary_accuracy: 0.9087\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1463 - precision: 0.7824 - binary_accuracy: 0.9343\n",
      "Epoch 00020: val_precision improved from 0.75525 to 0.76346, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1463 - precision: 0.7824 - binary_accuracy: 0.9343 - val_loss: 0.2425 - val_precision: 0.7635 - val_binary_accuracy: 0.9092\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1463 - precision: 0.7868 - binary_accuracy: 0.9345\n",
      "Epoch 00021: val_precision improved from 0.76346 to 0.76760, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1463 - precision: 0.7868 - binary_accuracy: 0.9345 - val_loss: 0.2424 - val_precision: 0.7676 - val_binary_accuracy: 0.9095\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1463 - precision: 0.7884 - binary_accuracy: 0.9346\n",
      "Epoch 00022: val_precision improved from 0.76760 to 0.76944, saving model to 3dres_aspp_MR.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "200/200 [==============================] - 244s 1s/step - loss: 0.1463 - precision: 0.7884 - binary_accuracy: 0.9346 - val_loss: 0.2421 - val_precision: 0.7694 - val_binary_accuracy: 0.9097\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1462 - precision: 0.7870 - binary_accuracy: 0.9345\n",
      "Epoch 00023: val_precision did not improve from 0.76944\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1462 - precision: 0.7870 - binary_accuracy: 0.9345 - val_loss: 0.2433 - val_precision: 0.7685 - val_binary_accuracy: 0.9095\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1459 - precision: 0.7882 - binary_accuracy: 0.9346\n",
      "Epoch 00024: val_precision did not improve from 0.76944\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1459 - precision: 0.7882 - binary_accuracy: 0.9346 - val_loss: 0.2416 - val_precision: 0.7688 - val_binary_accuracy: 0.9097\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1461 - precision: 0.7881 - binary_accuracy: 0.9346\n",
      "Epoch 00025: val_precision improved from 0.76944 to 0.76962, saving model to 3dres_aspp_MR.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "200/200 [==============================] - 244s 1s/step - loss: 0.1461 - precision: 0.7881 - binary_accuracy: 0.9346 - val_loss: 0.2422 - val_precision: 0.7696 - val_binary_accuracy: 0.9096\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1458 - precision: 0.7884 - binary_accuracy: 0.9347\n",
      "Epoch 00026: val_precision did not improve from 0.76962\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1458 - precision: 0.7884 - binary_accuracy: 0.9347 - val_loss: 0.2421 - val_precision: 0.7680 - val_binary_accuracy: 0.9096\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1458 - precision: 0.7877 - binary_accuracy: 0.9347\n",
      "Epoch 00027: val_precision did not improve from 0.76962\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1458 - precision: 0.7877 - binary_accuracy: 0.9347 - val_loss: 0.2422 - val_precision: 0.7690 - val_binary_accuracy: 0.9096\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1464 - precision: 0.7875 - binary_accuracy: 0.9346\n",
      "Epoch 00028: val_precision did not improve from 0.76962\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1464 - precision: 0.7875 - binary_accuracy: 0.9346 - val_loss: 0.2420 - val_precision: 0.7679 - val_binary_accuracy: 0.9096\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1458 - precision: 0.7885 - binary_accuracy: 0.9348\n",
      "Epoch 00029: val_precision improved from 0.76962 to 0.77138, saving model to 3dres_aspp_MR.h5\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1458 - precision: 0.7885 - binary_accuracy: 0.9348 - val_loss: 0.2412 - val_precision: 0.7714 - val_binary_accuracy: 0.9098\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1459 - precision: 0.7894 - binary_accuracy: 0.9348\n",
      "Epoch 00030: val_precision did not improve from 0.77138\n",
      "200/200 [==============================] - 228s 1s/step - loss: 0.1459 - precision: 0.7894 - binary_accuracy: 0.9348 - val_loss: 0.2420 - val_precision: 0.7690 - val_binary_accuracy: 0.9096\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data1,\n",
    "    mask1,\n",
    "    batch_size=2,\n",
    "    epochs=15,\n",
    "    validation_data=(data1_v, mask1_v),\n",
    "    callbacks=cp_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('3dres_aspp_MR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('3dresnet_NoTuning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "0\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "1\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "2\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "3\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "4\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "5\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "6\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "7\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "8\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "9\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "10\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "11\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "12\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "13\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'VertSeg_train/images_222_t'\n",
    "mask_dir = 'VertSeg_train/masks_222_t'\n",
    "data_out_dir = 'VertSeg_train/test/cropped_image'\n",
    "mask_out_dir = 'VertSeg_train/test/cropped_mask'\n",
    "output_dir = 'VertSeg_train/test/out'\n",
    "\n",
    "test_image, test_mask = load_data_test(data_dir,mask_dir, data_out_dir, mask_out_dir)\n",
    "results = model.predict(test_image, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test(out_data_path, out_path):\n",
    "\n",
    "    for files in os.walk(out_data_path):\n",
    "        files1 = files\n",
    "        files1 = list(files1)\n",
    "        files1[2].sort()\n",
    "        for i in range(len(files1[2])):\n",
    "            if files1[2][i].split('.')[-1] == 'nii':\n",
    "                image = sitk.ReadImage(files1[0] + '/' + files1[2][i], imageIO=\"NiftiImageIO\")\n",
    "                image_spacing = image.GetSpacing()\n",
    "                                        \n",
    "                msk_temp = sitk.GetImageFromArray(results[i])\n",
    "                msk_temp.SetSpacing(image_spacing)\n",
    "                sitk.WriteImage(msk_temp, out_path + '/' + str(i) +'.nii')\n",
    "\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "write_test(data_out_dir, 'VertSeg_train/test/out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-2.1.0",
   "language": "python",
   "name": "tensorflow-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
