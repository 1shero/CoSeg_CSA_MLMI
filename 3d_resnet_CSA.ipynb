{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pip\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 84.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.1.1\n",
      "    Uninstalling pip-20.1.1:\n",
      "      Successfully uninstalled pip-20.1.1\n",
      "Successfully installed pip-21.0.1\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting wrapt\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting enum34\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/63/f6/ccb1c83687756aeabbf3ca0f213508fcfb03883ff200d201b3a4c60cedcc/enum34-1.1.10-py3-none-any.whl (11 kB)\n",
      "Collecting simplejson\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting netaddr\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ff/cd/9cdfea8fc45c56680b798db6a55fa60a22e2d3d3ccf54fc729d083b50ce4/netaddr-0.8.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 60.3 MB/s eta 0:00:01██████████████▍         | 2.3 MB 60.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/70/06/849cc805ac6332210083f2114a95b22ee252ce81ed4e1be4f1d2b87c9108/setuptools-54.0.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 25.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 20.0 MB/s eta 0:00:01.8 MB 20.0 MB/s eta 0:00:01MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b6/c0/442d9d87e0da00bf856ef6dd4916f84a2d710b5f1a367d42d7f3c4e99a6c/Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 23.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/f5/6e/a5c7a7147407a318cb421d10d84bb2049e81d0b7472eb0a91a30b9ea24a6/importlib_resources-5.1.1-py3-none-any.whl (25 kB)\n",
      "Collecting zipp>=0.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=68106 sha256=df9572e5a2c920f2a0b770260c916b4331eb4fc8109a99ea4a7c942cf3fa352e\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/2e/15/15/1d0000a58c51f3e43a85ab35ff995e48ee66f5458b146c5d03\n",
      "Successfully built wrapt\n",
      "Installing collected packages: zipp, pillow, numpy, importlib-resources, wrapt, simplejson, setuptools, netaddr, imageio, enum34\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.1.6 requires pandas>=0.24.2, but you have pandas 0.22.0 which is incompatible.\n",
      "modelarts 1.1.6 requires urllib3==1.21.1, but you have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "Successfully installed enum34-1.1.10 imageio-2.9.0 importlib-resources-5.1.1 netaddr-0.8.0 numpy-1.19.5 pillow-8.1.0 setuptools-54.0.0 simplejson-3.17.2 wrapt-1.12.1 zipp-3.4.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting matplotlib==2.2.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.6 MB 20.1 MB/s eta 0:00:01████▍                | 6.1 MB 20.1 MB/s eta 0:00:01████████▌    | 10.8 MB 20.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (2.6.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (2.2.0)\n",
      "Requirement already satisfied: pytz in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (2017.3)\n",
      "Requirement already satisfied: six>=1.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib==2.2.3) (1.14.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 90.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 2.1.2\n",
      "    Uninstalling matplotlib-2.1.2:\n",
      "      Successfully uninstalled matplotlib-2.1.2\n",
      "Successfully installed kiwisolver-1.3.1 matplotlib-2.2.3\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (3.12)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from h5py) (1.19.5)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from h5py) (1.14.0)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scikit-image in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (0.13.1)\n",
      "Collecting scikit-image\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 80.2 MB/s eta 0:00:01████▍                          | 2.1 MB 80.2 MB/s eta 0:00:01�█████████████████████▊| 12.3 MB 80.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (2.2.3)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/59/bb/d2b85265ec9fa3c1922210c9393d4cdf7075cc87cce6fe671d7455f80fbc/PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 21.1 MB/s eta 0:00:01��███████████████▌      | 3.5 MB 21.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (2.1)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (2.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/42/6b/93a8ee61c6fbe20fa9c17928bd3b80484902b7fd454cecaffba42f5052cb/tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 43.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-image) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: six>=1.10 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: pytz in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2017.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.6.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.2.1)\n",
      "Installing collected packages: tifffile, PyWavelets, scikit-image\n",
      "  Attempting uninstall: PyWavelets\n",
      "    Found existing installation: PyWavelets 0.5.2\n",
      "    Uninstalling PyWavelets-0.5.2:\n",
      "      Successfully uninstalled PyWavelets-0.5.2\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.13.1\n",
      "    Uninstalling scikit-image-0.13.1:\n",
      "      Successfully uninstalled scikit-image-0.13.1\n",
      "Successfully installed PyWavelets-1.1.1 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "Found existing installation: numpy 1.19.5\n",
      "Uninstalling numpy-1.19.5:\n",
      "  Successfully uninstalled numpy-1.19.5\n",
      "Found existing installation: numpy 1.18.4\n",
      "Uninstalling numpy-1.18.4:\n",
      "  Successfully uninstalled numpy-1.18.4\n",
      "Found existing installation: numpy 1.20.1\n",
      "Uninstalling numpy-1.20.1:\n",
      "  Successfully uninstalled numpy-1.20.1\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting numpy==1.18.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 20.9 MB/s eta 0:00:01B/s eta 0:00:01          | 9.4 MB 20.9 MB/s eta 0:00:01█▎        | 14.7 MB 20.9 MB/s eta 0:00:01��█████████████████████████████▌| 19.9 MB 20.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.1.6 requires pandas>=0.24.2, but you have pandas 0.22.0 which is incompatible.\n",
      "modelarts 1.1.6 requires urllib3==1.21.1, but you have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.18.4\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pyarrow==0.16.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/00/d2/695bab1e1e7a4554b6dbd287d55cca096214bd441037058a432afd724bb1/pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.1 MB 11.0 MB/s eta 0:00:0100:060:05                | 15.0 MB 11.0 MB/s eta 0:00:05��███▏                     | 20.0 MB 11.0 MB/s eta 0:00:04�██▏                | 30.0 MB 11.0 MB/s eta 0:00:04��████████              | 35.7 MB 11.0 MB/s eta 0:00:03 MB 11.0 MB/s eta 0:00:03█████▌        | 46.4 MB 11.0 MB/s eta 0:00:02█████▋   | 56.5 MB 11.0 MB/s eta 0:00:01�██▏| 61.5 MB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pyarrow==0.16.0) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pyarrow==0.16.0) (1.18.4)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-0.16.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting protobuf==3.12.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/35/6c/d1cf8521f94b332851cf95dbf679a72271ba85b367e2283b9f5f6cdf98bc/protobuf-3.12.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from protobuf==3.12.0) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from protobuf==3.12.0) (54.0.0)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.1\n",
      "    Uninstalling protobuf-3.12.1:\n",
      "      Successfully uninstalled protobuf-3.12.1\n",
      "Successfully installed protobuf-3.12.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting SimpleITK\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/cc/85/6a7ce61f07cdaca722dd64f028b5678fb0a9e1bf66f534c2f8dd2eb78490/SimpleITK-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (47.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.4 MB 84.7 MB/s eta 0:00:01K     |▌                               | 788 kB 84.7 MB/s eta 0:00:01                | 11.2 MB 84.7 MB/s eta 0:00:01███▉                     | 16.0 MB 84.7 MB/s eta 0:00:01███▋                 | 21.6 MB 84.7 MB/s eta 0:00:01  | 26.3 MB 84.7 MB/s eta 0:00:01��████████████████████▋          | 32.1 MB 84.7 MB/s eta 0:00:01[K     |█████████████████████████▏      | 37.4 MB 84.7 MB/s eta 0:00:017 MB 84.7 MB/s eta 0:00:01████████| 47.4 MB 84.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: SimpleITK\n",
      "Successfully installed SimpleITK-2.0.2\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scipy in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scipy) (1.18.4)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pydot\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ea/76/75b1bb82e9bad3e3d656556eaa353d8cd17c4254393b08ec9786ac8ed273/pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pydot) (2.2.0)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (0.19.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 86.8 MB/s eta 0:00:01.9 MB 86.8 MB/s eta 0:00:01MB/s eta 0:00:01   | 13.7 MB 86.8 MB/s eta 0:00:01��████████▍    | 19.0 MB 86.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from scikit-learn) (1.18.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 78.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.1 threadpoolctl-2.1.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting keras_unet\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b0/f6/783d69bd0c5b250abcf0d0f187ce7b3e2cc2332315068d2fd14662b0471e/keras_unet-0.1.2-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: keras-unet\n",
      "Successfully installed keras-unet-0.1.2\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: opencv-python in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (3.4.0.12)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from opencv-python) (1.18.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install -U --ignore-installed wrapt enum34 simplejson netaddr imageio setuptools\n",
    "# !pip install matplotlib==2.2.3\n",
    "# !pip install pyyaml h5py\n",
    "\n",
    "# !pip install --upgrade scikit-image\n",
    "# !pip uninstall numpy --yes\n",
    "# !pip uninstall numpy --yes\n",
    "# !pip uninstall numpy --yes\n",
    "# !pip install numpy==1.18.4\n",
    "\n",
    "# !pip install pyarrow==0.16.0\n",
    "# !pip install protobuf==3.12.0\n",
    "\n",
    "# !pip install SimpleITK\n",
    "# !pip install scipy\n",
    "# !pip install pydot\n",
    "\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install keras_unet\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.1.0\n",
      "Uninstalling tensorflow-2.1.0:\n",
      "  Successfully uninstalled tensorflow-2.1.0\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting tensorflow-gpu==2.3.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0f/11/763f55d3d15efd778ef24453f126e6c33635680e5a2bb346da3fab5997cb/tensorflow_gpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |███████████████████████████▉    | 278.9 MB 63.0 MB/s eta 0:00:01   |▋                               | 6.3 MB 17.9 MB/s eta 0:00:18▏                              | 11.2 MB 17.9 MB/s eta 0:00:1817                       | 22.1 MB 17.9 MB/s eta 0:00:17                       | 27.8 MB 17.9 MB/s eta 0:00:17.9 MB/s eta 0:00:17 MB 17.9 MB/s eta 0:00:16 |████▍                           | 44.3 MB 17.9 MB/s eta 0:00:16 |█████                           | 49.1 MB 17.9 MB/s eta 0:00:16    | 54.3 MB 17.9 MB/s eta 0:00:15    |██████                          | 59.9 MB 17.9 MB/s eta 0:00:155                     | 75.7 MB 17.9 MB/s eta 0:00:141414               | 93.5 MB 17.9 MB/s eta 0:00:13               | 99.2 MB 73.1 MB/s eta 0:00:04MB/s eta 0:00:03MB/s eta 0:00:03█▋                    | 116.2 MB 73.1 MB/s eta 0:00:03��██▏                   | 121.4 MB 73.1 MB/s eta 0:00:03        | 132.5 MB 73.1 MB/s eta 0:00:03��█▉                  | 138.0 MB 73.1 MB/s eta 0:00:03�█▎                 | 143.2 MB 73.1 MB/s eta 0:00:03/s eta 0:00:03 |████████████████                | 160.0 MB 73.1 MB/s eta 0:00:03        | 169.7 MB 73.1 MB/s eta 0:00:03��█████████████▌              | 175.2 MB 73.1 MB/s eta 0:00:02��██████████████              | 180.9 MB 73.1 MB/s eta 0:00:02MB/s eta 0:00:02�██████             | 190.3 MB 73.1 MB/s eta 0:00:02          | 194.0 MB 73.1 MB/s eta 0:00:02          | 199.3 MB 63.0 MB/s eta 0:00:02██████████████▎           | 203.4 MB 63.0 MB/s eta 0:00:02██████████████▉           | 208.8 MB 63.0 MB/s eta 0:00:02:00:02MB 63.0 MB/s eta 0:00:02        | 223.9 MB 63.0 MB/s eta 0:00:02        | 228.3 MB 63.0 MB/s eta 0:00:02�██████████▎        | 233.1 MB 63.0 MB/s eta 0:00:02�██████████▉        | 238.7 MB 63.0 MB/s eta 0:00:02██████████████████████▍       | 243.8 MB 63.0 MB/s eta 0:00:02�███████████▊       | 247.8 MB 63.0 MB/s eta 0:00:02MB/s eta 0:00:02| 257.8 MB 63.0 MB/s eta 0:00:01[K     |██████████████████████████▏     | 261.9 MB 63.0 MB/s eta 0:00:01��██▊     | 267.8 MB 63.0 MB/s eta 0:00:01��█████▎    | 272.9 MB 63.0 MB/s eta 0:00:01█████████▌    | 275.4 MB 63.0 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 61.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (0.9.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.18.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (3.2.1)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 86.4 MB/s eta 0:00:01████████▏                 | 1.3 MB 86.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (3.12.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 30 kB/s eta 0:00:01�███▊               | 5.6 MB 8.3 MB/s eta 0:00:01 |███████████████████▋            | 6.5 MB 8.3 MB/s eta 0:00:01.5 MB 30 kB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.29.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (0.30.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow-gpu==2.3.0) (54.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.2.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/1a/c1/499e600ba0c618b451cd9c425ae1c177249940a2086316552fee7d86c954/tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 22.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.14.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2018.1.18)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4.0)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorflow-estimator, tensorboard, h5py, gast, astunparse, tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.7.1\n",
      "    Uninstalling h5py-2.7.1:\n",
      "      Successfully uninstalled h5py-2.7.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed astunparse-1.6.3 gast-0.3.3 h5py-2.10.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.0\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting keras==2.4.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (1.18.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from keras==2.4.3) (1.4.1)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from h5py->keras==2.4.3) (1.14.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 84.6 MB/s eta 0:00:01███▌                       | 2.7 MB 84.6 MB/s eta 0:00:01██████▍       | 7.7 MB 84.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pandas==0.24.2) (1.18.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pandas==0.24.2) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from pandas==0.24.2) (2017.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.24.2) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.1.6 requires urllib3==1.21.1, but you have urllib3 1.22 which is incompatible.\u001b[0m\n",
      "Successfully installed pandas-0.24.2\n",
      "Found existing installation: urllib3 1.22\n",
      "Uninstalling urllib3-1.22:\n",
      "  Successfully uninstalled urllib3-1.22\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: urllib3==1.21.1 in /home/ma-user/modelarts-sdk (1.21.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall tensorflow --yes\n",
    "# !pip uninstall tensorflow --yes\n",
    "\n",
    "# !pip uninstall tensorflow-gpu --yes\n",
    "# !pip uninstall tensorflow-gpu --yes\n",
    "\n",
    "# !pip uninstall keras --yes\n",
    "# !pip uninstall keras --yes\n",
    "\n",
    "# !pip install tensorflow-gpu==2.3.0\n",
    "# !pip install --upgrade keras==2.4.3\n",
    "\n",
    "# !pip install pandas==0.24.2\n",
    "# !pip uninstall urllib3 --yes\n",
    "# !pip install urllib3==1.21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding3D, BatchNormalization, Flatten, Conv3D, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D, Concatenate, GlobalAveragePooling3D,Multiply\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from load_preprocess_util import *\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filem:\t ('VertSeg_train/masks_222_t', ['.ipynb_checkpoints'], ['mask007.nii', 'mask013.nii', 'mask008.nii', 'mask004.nii', 'mask006.nii', 'mask005.nii', 'mask012.nii', 'mask009.nii', 'mask001.nii', 'mask002.nii', 'mask010.nii', 'mask014.nii', 'mask015.nii', 'mask003.nii', 'mask011.nii'])\n",
      "filem:\t ('VertSeg_train/masks_222_t/.ipynb_checkpoints', [], [])\n",
      "files2:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii']\n",
      "files1:\t ['image001.nii', 'image002.nii', 'image003.nii', 'image004.nii', 'image005.nii', 'image006.nii', 'image007.nii', 'image008.nii', 'image009.nii', 'image010.nii', 'image011.nii', 'image012.nii', 'image013.nii', 'image014.nii', 'image015.nii']\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 0\n",
      "mask001.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask001.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "0\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 1\n",
      "mask002.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask002.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "1\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 2\n",
      "mask003.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask003.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "2\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 3\n",
      "mask004.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask004.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "3\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 4\n",
      "mask005.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask005.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "4\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 5\n",
      "mask006.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask006.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "5\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 6\n",
      "mask007.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask007.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "6\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 7\n",
      "mask008.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask008.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "7\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 8\n",
      "mask009.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask009.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 9\n",
      "mask010.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask010.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "9\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 10\n",
      "mask011.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask011.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "10\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 11\n",
      "mask012.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask012.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "11\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 12\n",
      "mask013.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask013.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "12\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 13\n",
      "mask014.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask014.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "13\n",
      "files22:\t ['mask001.nii', 'mask002.nii', 'mask003.nii', 'mask004.nii', 'mask005.nii', 'mask006.nii', 'mask007.nii', 'mask008.nii', 'mask009.nii', 'mask010.nii', 'mask011.nii', 'mask012.nii', 'mask013.nii', 'mask014.nii', 'mask015.nii'] \t 14\n",
      "mask015.nii\n",
      "nii\n",
      "VertSeg_train/masks_222_t/mask015.nii\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "14\n",
      "files1:\t []\n",
      "['mask1.nii', 'mask2.nii', 'mask3.nii', 'mask4.nii', 'mask5.nii']\n",
      "[]\n",
      "['image1.nii', 'image2.nii', 'image3.nii', 'image4.nii', 'image5.nii']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b6988e485a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_MR_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdata1_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir1_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir1_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/load_preprocess_util.py\u001b[0m in \u001b[0;36mload_MR_data\u001b[0;34m(data_path, mask_path)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;31m#image = np.array(image, dtype='float16')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mfiles2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nii'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfiles2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageIO\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NiftiImageIO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_dir1 = 'VertSeg_train/images_222_t'\n",
    "mask_dir1 = 'VertSeg_train/masks_222_t'\n",
    "data_dir2 = 'MRI/images'\n",
    "mask_dir2 = 'MRI/masks'\n",
    "\n",
    "data_dir1_v = 'VertSeg_train/images_222_t_v'\n",
    "mask_dir1_v = 'VertSeg_train/masks_222_t_v'\n",
    "data_dir2_v = 'MRI/images_v'\n",
    "mask_dir2_v = 'MRI/masks_v'\n",
    "\n",
    "data1, mask1 = load_data(data_dir1, mask_dir1)\n",
    "data2, mask2 = load_MR_data(data_dir2, mask_dir2)\n",
    "\n",
    "data1_v, mask1_v = load_data(data_dir1_v, mask_dir1_v)\n",
    "data2_v, mask2_v = load_MR_data(data_dir2_v, mask_dir2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, index, s = 2):\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'+'_'+index\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'+'_'+index\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv3D(F1, (1, 1, 1), strides = (s,s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F2, kernel_size = (f, f, f), strides = (1,1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F3, kernel_size = (1, 1, 1), strides = (1,1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv3D(filters = F3, kernel_size = (1, 1 ,1), strides = (s,s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 4, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block, index):\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'+'_'+index\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'+'_'+index\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv3D(filters = F1, kernel_size = (1, 1, 1), strides = (1,1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F2, kernel_size = (f, f,f), strides = (1,1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv3D(filters = F3, kernel_size = (1, 1,1), strides = (1,1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 4, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.ones((5,1, 1, 1, 256))\n",
    "# b = resize_trilinear(a,[3, 16, 16])\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utilities for DeepLab\n",
    "Lei Mao\n",
    "Department of Computer Science\n",
    "University of Chicago\n",
    "dukeleimao@gmail.com\n",
    "'''\n",
    "\n",
    "def atrous_spatial_pyramid_pooling(inputs,index, filters=256, regularizer=None):\n",
    "    '''\n",
    "    Atrous Spatial Pyramid Pooling (ASPP) Block\n",
    "    '''\n",
    "    print('input: ',inputs.shape)\n",
    "    pool_height = inputs.shape[1]\n",
    "    pool_width = inputs.shape[2]\n",
    "    pool_depth = inputs.shape[3]\n",
    "\n",
    "    resize_height = pool_height\n",
    "    resize_width = pool_width\n",
    "    resize_depth = pool_depth\n",
    "\n",
    "    # Atrous Spatial Pyramid Pooling\n",
    "    # Atrous 1x1\n",
    "    aspp1x1 = Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer, name='aspp1x1'+'_'+index)(inputs)\n",
    "    # Atrous 3x3, rate = 6\n",
    "    aspp3x3_1 = Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same', dilation_rate=(6, 6, 6), kernel_regularizer=regularizer, name='aspp3x3_1'+'_'+index)(inputs)\n",
    "    # Atrous 3x3, rate = 12\n",
    "    aspp3x3_2 = Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same', dilation_rate=(12, 12, 12), kernel_regularizer=regularizer, name='aspp3x3_2'+'_'+index)(inputs)\n",
    "    # Atrous 3x3, rate = 18\n",
    "    aspp3x3_3 = Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same', dilation_rate=(18, 18, 18), kernel_regularizer=regularizer, name='aspp3x3_3'+'_'+index)(inputs)\n",
    "\n",
    "    # Image Level Pooling\n",
    "    image_feature = tf.reduce_mean(inputs, [1, 2, 3], keepdims=True)\n",
    "    image_feature = Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same',name='image_feature'+'_'+index)(image_feature)\n",
    "    image_feature = keras.layers.UpSampling3D(size=(resize_height, resize_width, resize_depth))(image_feature)\n",
    "    # Merge Poolings\n",
    "    print(aspp1x1.shape, aspp3x3_1.shape, aspp3x3_2.shape, aspp3x3_3.shape, image_feature.shape)\n",
    "    outputs = tf.concat(values=[aspp1x1, aspp3x3_1, aspp3x3_2, aspp3x3_3, image_feature], axis=4, name='aspp_pools'+'_'+index)\n",
    "    outputs = Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer, name='aspp_outputs'+'_'+index)(outputs)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(index, input_shape=(160, 160, 160, 2),regularizer=None):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding3D((3, 3, 3))(X_input)\n",
    "\n",
    "    X = Conv3D(64, (7, 7,7), strides=(2, 2,2), name='conv1'+'_'+index, kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=4, name='bn_conv1'+'_'+index)(X)\n",
    "    X = Activation('relu')(X)    \n",
    "    X = ZeroPadding3D((1, 1, 1))(X)\n",
    "    X = MaxPooling3D((3, 3,3), strides=(2, 2,2))(X)\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', index=index, s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b', index=index)\n",
    "    low_res_feature = identity_block(X, 3, [64, 64, 256], stage=2, block='c', index=index)\n",
    "\n",
    "    X = convolutional_block(low_res_feature, f = 3, filters = [128, 128, 512], stage = 3, block='a', index=index, s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b', index=index)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c', index=index)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d', index=index)\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', index=index, s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b', index=index)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c', index=index)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d', index=index)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e', index=index)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f', index=index)\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', index=index, s = 1)#key\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b', index=index)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c', index=index)\n",
    "\n",
    "    pools = atrous_spatial_pyramid_pooling(inputs=X, filters=256, index=index)\n",
    "    \n",
    "    low_res_feature = Conv3D(filters=48, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer,name='low_res_feature'+'_'+index)(low_res_feature)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = [pools,low_res_feature], name='ResNet50'+'_'+index)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  (None, 2, 16, 16, 2048)\n",
      "(None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256)\n",
      "input:  (None, 2, 16, 16, 2048)\n",
      "(None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256) (None, 2, 16, 16, 256)\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model1 = ResNet50(index='model0_', input_shape=(32, 256, 256, 1)) #, regularizer=regularizers.l2(0.001)\n",
    "model2 = ResNet50(index='model1_', input_shape=(32, 256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSA\n",
    "def CSA(input1,input2,channel_num=256):        \n",
    "\n",
    "    #1，2 refers to imput; a,m refers to pooling\n",
    "    out1 = Conv3D(channel_num,3, padding='same')(input1)\n",
    "    out2 = Conv3D(channel_num,3, padding='same')(input2)\n",
    "    \n",
    "    ChanA_1 = BatchNormalization()(out1)\n",
    "    ChanA_1 = Activation('sigmoid')(ChanA_1)\n",
    "    ChanA_2 = BatchNormalization()(out2)\n",
    "    ChanA_2 = Activation('sigmoid')(ChanA_2)\n",
    "\n",
    "    # Channel Attention\n",
    "\n",
    "    ChanA_1_a = GlobalAveragePooling3D()(ChanA_1)\n",
    "    ChanA_2_a = GlobalAveragePooling3D()(ChanA_2)\n",
    "    ChanA_1_m = GlobalMaxPooling3D()(ChanA_1)\n",
    "    ChanA_2_m = GlobalMaxPooling3D()(ChanA_2)\n",
    "\n",
    "    ChanA_a = Concatenate(axis=-1)([ChanA_1_a, ChanA_2_a])\n",
    "    ChanA_m = Concatenate(axis=-1)([ChanA_1_m, ChanA_2_m])\n",
    "\n",
    "    ChanA_a = keras.layers.Dense(channel_num, activation='sigmoid')(ChanA_a)\n",
    "    ChanA_m = keras.layers.Dense(channel_num, activation='sigmoid')(ChanA_m)\n",
    "\n",
    "    ChanA = keras.layers.Add()([ChanA_a, ChanA_m])\n",
    "\n",
    "    ChanA = Activation('sigmoid')(ChanA)\n",
    "\n",
    "    out1 = Multiply()([ChanA_1, ChanA])\n",
    "    out2 = Multiply()([ChanA_2, ChanA])\n",
    "    \n",
    "    print(out1.shape,out2.shape)\n",
    "    \n",
    "    # Spatical Attention\n",
    "\n",
    "    d_avg_pooling = keras.layers.Lambda(lambda x: tf.math.divide(tf.reduce_sum(x,axis=-1),channel_num),name='d_avg_pooling') \n",
    "    d_max_pooling = keras.layers.Lambda(lambda x: tf.reduce_max(x,axis=-1),name='d_max_pooling')\n",
    "\n",
    "    SpaA_1_a =  d_avg_pooling(out1)\n",
    "    SpaA_1_m =  d_max_pooling(out1)\n",
    "    \n",
    "    print(SpaA_1_a.shape, SpaA_1_m.shape)\n",
    "    \n",
    "    SpaA_1 = keras.layers.Lambda(lambda x: tf.stack([x[0],x[1]],axis=-1),name='stack1')([SpaA_1_a, SpaA_1_m])\n",
    "    \n",
    "    print(SpaA_1.shape)\n",
    "    \n",
    "    SpaA_1 = Conv3D(1, 3, padding=\"same\", activation='sigmoid')(SpaA_1)\n",
    "\n",
    "    out1 = Multiply()([out1,SpaA_1])\n",
    "\n",
    "    SpaA_2_a =  d_avg_pooling(out2)\n",
    "    SpaA_2_m =  d_max_pooling(out2)\n",
    "    SpaA_2 = keras.layers.Lambda(lambda x: tf.stack([x[0],x[1]],axis=-1),name='stack2')([SpaA_2_a, SpaA_2_m])\n",
    "    SpaA_2 = Conv3D(1, 3, padding=\"same\",activation='sigmoid')(SpaA_2)\n",
    "\n",
    "    out2 = Multiply()([out2,SpaA_2])\n",
    "\n",
    "    return out1, out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2, 16, 16, 256) (None, 2, 16, 16, 256)\n",
      "(None, 2, 16, 16) (None, 2, 16, 16)\n",
      "(None, 2, 16, 16, 2)\n"
     ]
    }
   ],
   "source": [
    "regularizer = None\n",
    "X1 = model1.output[0]\n",
    "X2 = model2.output[0]\n",
    "low_res_feature1 = model1.output[1]\n",
    "low_res_feature2 = model2.output[1]\n",
    "\n",
    "\n",
    "X1,X2 = CSA(X1,X2)\n",
    "\n",
    "X1 = keras.layers.UpSampling3D(size=4)(X1)\n",
    "high_low_res1 = Concatenate(axis=-1)([X1, low_res_feature1])\n",
    "\n",
    "X1 = Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(high_low_res1)\n",
    "X1 = BatchNormalization(axis = 4)(X1)\n",
    "X1 = Activation('sigmoid')(X1)\n",
    "\n",
    "X1 = Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(X1)\n",
    "X1 = BatchNormalization(axis = 4)(X1)\n",
    "X1 = Activation('sigmoid')(X1)\n",
    "\n",
    "X1 = keras.layers.UpSampling3D(size=2)(X1)\n",
    "X1 = Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(X1)\n",
    "#X = BatchNormalization(axis = 4)(X)\n",
    "X1 = Activation('sigmoid')(X1)\n",
    "\n",
    "X1 = keras.layers.UpSampling3D(size=2)(X1)\n",
    "X1 = Conv3D(filters=1, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer)(X1)\n",
    "out1 = Activation('sigmoid')(X1)\n",
    "\n",
    "\n",
    "\n",
    "X2 = keras.layers.UpSampling3D(size=4)(X2)\n",
    "high_low_res2 = Concatenate(axis=-1)([X2, low_res_feature2])\n",
    "\n",
    "X2 = Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(high_low_res2)\n",
    "X2 = BatchNormalization(axis = 4)(X2)\n",
    "X2 = Activation('sigmoid')(X2)\n",
    "\n",
    "X2 = Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(X2)\n",
    "X2 = BatchNormalization(axis = 4)(X2)\n",
    "X2 = Activation('sigmoid')(X2)\n",
    "\n",
    "X2 = keras.layers.UpSampling3D(size=2)(X2)\n",
    "X2 = Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', kernel_regularizer=regularizer)(X2)\n",
    "X2 = Activation('sigmoid')(X2)\n",
    "\n",
    "X2 = keras.layers.UpSampling3D(size=2)(X2)\n",
    "X2 = Conv3D(filters=1, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=regularizer)(X2)\n",
    "out2 = Activation('sigmoid')(X2)\n",
    "\n",
    "\n",
    "CSA_model = Model(inputs = [model1.input,model2.input], outputs = [out1,out2], name='ResNet50_CSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "from time import strftime, gmtime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
    "checkpoint_path = \"3dres_aspp_CSA_kfold.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = [ModelCheckpoint(filepath=checkpoint_path, verbose=1, monitor='val_loss', save_best_only=True, mode='min'),#save_weights_only=True\n",
    "               #keras.callbacks.LearningRateScheduler(lr_decayed_fn), \n",
    "               CSVLogger(\"./csv/model_history_log_{}.csv\".format(strftime(\"%Y_%b_%d, %H+8:%M:%S\", gmtime())), append=True),\n",
    "              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n",
    "                #tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "CSA_model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[keras.metrics.Precision(),keras.metrics.BinaryAccuracy()]) #keras.metrics.MeanIoU(num_classes=2), keras.metrics.Precision(), iou, iou_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0969 - activation_104_loss: 0.0330 - activation_108_loss: 0.0639 - activation_104_precision: 0.6749 - activation_104_binary_accuracy: 0.9842 - activation_108_precision: 0.8954 - activation_108_binary_accuracy: 0.9719\n",
      "Epoch 00001: val_loss improved from inf to 0.32483, saving model to 3dres_aspp_CSA_kfold.h5\n",
      "100/100 [==============================] - 284s 3s/step - loss: 0.0969 - activation_104_loss: 0.0330 - activation_108_loss: 0.0639 - activation_104_precision: 0.6749 - activation_104_binary_accuracy: 0.9842 - activation_108_precision: 0.8954 - activation_108_binary_accuracy: 0.9719 - val_loss: 0.3248 - val_activation_104_loss: 0.0480 - val_activation_108_loss: 0.2768 - val_activation_104_precision: 0.6921 - val_activation_104_binary_accuracy: 0.9771 - val_activation_108_precision: 0.8340 - val_activation_108_binary_accuracy: 0.9196\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0940 - activation_104_loss: 0.0323 - activation_108_loss: 0.0617 - activation_104_precision: 0.6678 - activation_104_binary_accuracy: 0.9846 - activation_108_precision: 0.9013 - activation_108_binary_accuracy: 0.9727\n",
      "Epoch 00002: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0940 - activation_104_loss: 0.0323 - activation_108_loss: 0.0617 - activation_104_precision: 0.6678 - activation_104_binary_accuracy: 0.9846 - activation_108_precision: 0.9013 - activation_108_binary_accuracy: 0.9727 - val_loss: 0.3332 - val_activation_104_loss: 0.0497 - val_activation_108_loss: 0.2835 - val_activation_104_precision: 0.7430 - val_activation_104_binary_accuracy: 0.9759 - val_activation_108_precision: 0.8228 - val_activation_108_binary_accuracy: 0.9192\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0920 - activation_104_loss: 0.0315 - activation_108_loss: 0.0605 - activation_104_precision: 0.6749 - activation_104_binary_accuracy: 0.9850 - activation_108_precision: 0.9018 - activation_108_binary_accuracy: 0.9730\n",
      "Epoch 00003: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0920 - activation_104_loss: 0.0315 - activation_108_loss: 0.0605 - activation_104_precision: 0.6749 - activation_104_binary_accuracy: 0.9850 - activation_108_precision: 0.9018 - activation_108_binary_accuracy: 0.9730 - val_loss: 0.3480 - val_activation_104_loss: 0.0485 - val_activation_108_loss: 0.2994 - val_activation_104_precision: 0.7536 - val_activation_104_binary_accuracy: 0.9765 - val_activation_108_precision: 0.8353 - val_activation_108_binary_accuracy: 0.9174\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0896 - activation_104_loss: 0.0307 - activation_108_loss: 0.0589 - activation_104_precision: 0.6850 - activation_104_binary_accuracy: 0.9853 - activation_108_precision: 0.9041 - activation_108_binary_accuracy: 0.9738\n",
      "Epoch 00004: val_loss did not improve from 0.32483\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0896 - activation_104_loss: 0.0307 - activation_108_loss: 0.0589 - activation_104_precision: 0.6850 - activation_104_binary_accuracy: 0.9853 - activation_108_precision: 0.9041 - activation_108_binary_accuracy: 0.9738 - val_loss: 0.3622 - val_activation_104_loss: 0.0460 - val_activation_108_loss: 0.3162 - val_activation_104_precision: 0.7160 - val_activation_104_binary_accuracy: 0.9781 - val_activation_108_precision: 0.8294 - val_activation_108_binary_accuracy: 0.9156\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0884 - activation_104_loss: 0.0302 - activation_108_loss: 0.0582 - activation_104_precision: 0.6942 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9054 - activation_108_binary_accuracy: 0.9741\n",
      "Epoch 00005: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 240s 2s/step - loss: 0.0884 - activation_104_loss: 0.0302 - activation_108_loss: 0.0582 - activation_104_precision: 0.6942 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9054 - activation_108_binary_accuracy: 0.9741 - val_loss: 0.3517 - val_activation_104_loss: 0.0463 - val_activation_108_loss: 0.3055 - val_activation_104_precision: 0.7194 - val_activation_104_binary_accuracy: 0.9780 - val_activation_108_precision: 0.8185 - val_activation_108_binary_accuracy: 0.9165\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0875 - activation_104_loss: 0.0298 - activation_108_loss: 0.0577 - activation_104_precision: 0.7126 - activation_104_binary_accuracy: 0.9862 - activation_108_precision: 0.9057 - activation_108_binary_accuracy: 0.9742\n",
      "Epoch 00006: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0875 - activation_104_loss: 0.0298 - activation_108_loss: 0.0577 - activation_104_precision: 0.7126 - activation_104_binary_accuracy: 0.9862 - activation_108_precision: 0.9057 - activation_108_binary_accuracy: 0.9742 - val_loss: 0.3496 - val_activation_104_loss: 0.0464 - val_activation_108_loss: 0.3032 - val_activation_104_precision: 0.7153 - val_activation_104_binary_accuracy: 0.9779 - val_activation_108_precision: 0.8143 - val_activation_108_binary_accuracy: 0.9166\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0873 - activation_104_loss: 0.0300 - activation_108_loss: 0.0574 - activation_104_precision: 0.7038 - activation_104_binary_accuracy: 0.9859 - activation_108_precision: 0.9053 - activation_108_binary_accuracy: 0.9744\n",
      "Epoch 00007: val_loss did not improve from 0.32483\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0873 - activation_104_loss: 0.0300 - activation_108_loss: 0.0574 - activation_104_precision: 0.7038 - activation_104_binary_accuracy: 0.9859 - activation_108_precision: 0.9053 - activation_108_binary_accuracy: 0.9744 - val_loss: 0.3502 - val_activation_104_loss: 0.0464 - val_activation_108_loss: 0.3038 - val_activation_104_precision: 0.7175 - val_activation_104_binary_accuracy: 0.9778 - val_activation_108_precision: 0.8166 - val_activation_108_binary_accuracy: 0.9169\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0875 - activation_104_loss: 0.0302 - activation_108_loss: 0.0573 - activation_104_precision: 0.6893 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9049 - activation_108_binary_accuracy: 0.9743\n",
      "Epoch 00008: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 239s 2s/step - loss: 0.0875 - activation_104_loss: 0.0302 - activation_108_loss: 0.0573 - activation_104_precision: 0.6893 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9049 - activation_108_binary_accuracy: 0.9743 - val_loss: 0.3498 - val_activation_104_loss: 0.0464 - val_activation_108_loss: 0.3034 - val_activation_104_precision: 0.7137 - val_activation_104_binary_accuracy: 0.9779 - val_activation_108_precision: 0.8163 - val_activation_108_binary_accuracy: 0.9169\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0872 - activation_104_loss: 0.0298 - activation_108_loss: 0.0573 - activation_104_precision: 0.6958 - activation_104_binary_accuracy: 0.9858 - activation_108_precision: 0.9058 - activation_108_binary_accuracy: 0.9743\n",
      "Epoch 00009: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0872 - activation_104_loss: 0.0298 - activation_108_loss: 0.0573 - activation_104_precision: 0.6958 - activation_104_binary_accuracy: 0.9858 - activation_108_precision: 0.9058 - activation_108_binary_accuracy: 0.9743 - val_loss: 0.3489 - val_activation_104_loss: 0.0464 - val_activation_108_loss: 0.3025 - val_activation_104_precision: 0.7138 - val_activation_104_binary_accuracy: 0.9779 - val_activation_108_precision: 0.8166 - val_activation_108_binary_accuracy: 0.9170\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0875 - activation_104_loss: 0.0301 - activation_108_loss: 0.0574 - activation_104_precision: 0.6941 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9060 - activation_108_binary_accuracy: 0.9743\n",
      "Epoch 00010: val_loss did not improve from 0.32483\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0875 - activation_104_loss: 0.0301 - activation_108_loss: 0.0574 - activation_104_precision: 0.6941 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9060 - activation_108_binary_accuracy: 0.9743 - val_loss: 0.3464 - val_activation_104_loss: 0.0464 - val_activation_108_loss: 0.3000 - val_activation_104_precision: 0.7136 - val_activation_104_binary_accuracy: 0.9779 - val_activation_108_precision: 0.8148 - val_activation_108_binary_accuracy: 0.9173\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0871 - activation_104_loss: 0.0299 - activation_108_loss: 0.0572 - activation_104_precision: 0.6924 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9057 - activation_108_binary_accuracy: 0.9745\n",
      "Epoch 00011: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0871 - activation_104_loss: 0.0299 - activation_108_loss: 0.0572 - activation_104_precision: 0.6924 - activation_104_binary_accuracy: 0.9857 - activation_108_precision: 0.9057 - activation_108_binary_accuracy: 0.9745 - val_loss: 0.3472 - val_activation_104_loss: 0.0463 - val_activation_108_loss: 0.3009 - val_activation_104_precision: 0.7107 - val_activation_104_binary_accuracy: 0.9779 - val_activation_108_precision: 0.8153 - val_activation_108_binary_accuracy: 0.9172\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0868 - activation_104_loss: 0.0296 - activation_108_loss: 0.0572 - activation_104_precision: 0.6984 - activation_104_binary_accuracy: 0.9859 - activation_108_precision: 0.9062 - activation_108_binary_accuracy: 0.9744\n",
      "Epoch 00012: val_loss did not improve from 0.32483\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0868 - activation_104_loss: 0.0296 - activation_108_loss: 0.0572 - activation_104_precision: 0.6984 - activation_104_binary_accuracy: 0.9859 - activation_108_precision: 0.9062 - activation_108_binary_accuracy: 0.9744 - val_loss: 0.3454 - val_activation_104_loss: 0.0462 - val_activation_108_loss: 0.2992 - val_activation_104_precision: 0.7087 - val_activation_104_binary_accuracy: 0.9781 - val_activation_108_precision: 0.8148 - val_activation_108_binary_accuracy: 0.9174\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0872 - activation_104_loss: 0.0299 - activation_108_loss: 0.0573 - activation_104_precision: 0.6957 - activation_104_binary_accuracy: 0.9859 - activation_108_precision: 0.9066 - activation_108_binary_accuracy: 0.9744\n",
      "Epoch 00013: val_loss did not improve from 0.32483\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.0872 - activation_104_loss: 0.0299 - activation_108_loss: 0.0573 - activation_104_precision: 0.6957 - activation_104_binary_accuracy: 0.9859 - activation_108_precision: 0.9066 - activation_108_binary_accuracy: 0.9744 - val_loss: 0.3473 - val_activation_104_loss: 0.0462 - val_activation_108_loss: 0.3011 - val_activation_104_precision: 0.7105 - val_activation_104_binary_accuracy: 0.9780 - val_activation_108_precision: 0.8158 - val_activation_108_binary_accuracy: 0.9172\n",
      "Epoch 14/15\n",
      " 75/100 [=====================>........] - ETA: 53s - loss: 0.0897 - activation_104_loss: 0.0310 - activation_108_loss: 0.0587 - activation_104_precision: 0.6984 - activation_104_binary_accuracy: 0.9852 - activation_108_precision: 0.9051 - activation_108_binary_accuracy: 0.9737"
     ]
    }
   ],
   "source": [
    "history = CSA_model.fit(\n",
    "    [data1,data2],\n",
    "    [mask1,mask2],\n",
    "    batch_size=2,\n",
    "    epochs=15,\n",
    "    validation_data=([data1_v, data2_v],[mask1_v, mask2_v]),\n",
    "    callbacks=cp_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSA_model.save('3dres_aspp_CSA_kfold_tsu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSA_model = tf.keras.models.load_model('3dres_aspp_CSA_kfold_tsu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test reults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop first, than apply model on the cropped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "0\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "1\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "2\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "3\n",
      "(32, 256, 256)\n",
      "(32, 256, 256)\n",
      "4\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "(256, 32, 256)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from load_preprocess_util import *\n",
    "data_dir1 = 'VertSeg_train/images_222_t_v'\n",
    "mask_dir1 = 'VertSeg_train/masks_222_t_v'\n",
    "data_out_dir1 = 'VertSeg_train/test/cropped_image1'\n",
    "mask_out_dir1 = 'VertSeg_train/test/cropped_mask1'\n",
    "data_out_dir2 = 'VertSeg_train/test/cropped_image2'\n",
    "mask_out_dir2 = 'VertSeg_train/test/cropped_mask2'\n",
    "\n",
    "data_dir2 = 'MRI/images_v'\n",
    "mask_dir2 = 'MRI/masks_v'\n",
    "\n",
    "test_image1, test_mask1 = load_data_test(data_dir1,mask_dir1, data_out_dir1, mask_out_dir1)\n",
    "test_image2, test_mask2 = load_data_test_MR(data_dir2,mask_dir2, data_out_dir2, mask_out_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('3dres_aspp_CSA_kfold_tsu.h5')\n",
    "results = model.predict([test_image1,test_image2], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test(out_data_path, out_path,index):\n",
    "\n",
    "    for files in os.walk(out_data_path):\n",
    "        files1 = files\n",
    "        files1 = list(files1)\n",
    "        files1[2].sort()\n",
    "        for i in range(len(files1[2])):\n",
    "            if files1[2][i].split('.')[-1] == 'nii':\n",
    "                image = sitk.ReadImage(files1[0] + '/' + files1[2][i], imageIO=\"NiftiImageIO\")\n",
    "                image_spacing = image.GetSpacing()\n",
    "                                        \n",
    "                msk_temp = sitk.GetImageFromArray(results[index][i])\n",
    "                msk_temp.SetSpacing(image_spacing)\n",
    "                sitk.WriteImage(msk_temp, out_path + '/' + str(i) +'.nii')\n",
    "\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_MR(out_data_path, out_path,index):\n",
    "\n",
    "    for files in os.walk(out_data_path):\n",
    "        files1 = files\n",
    "        files1 = list(files1)\n",
    "        files1[2].sort()\n",
    "        for i in range(len(files1[2])):\n",
    "            if files1[2][i].split('.')[-1] == 'nii':\n",
    "                image = sitk.ReadImage(files1[0] + '/' + files1[2][i], imageIO=\"NiftiImageIO\")\n",
    "                image_spacing = image.GetSpacing()\n",
    "                image_dir = image.GetDirection()\n",
    "                                        \n",
    "                msk_temp = sitk.GetImageFromArray(np.transpose(results[index][i], (1, 0, 2,3)))\n",
    "                msk_temp.SetSpacing(image_spacing)\n",
    "                msk_temp.SetDirection(image_dir)\n",
    "                \n",
    "                sitk.WriteImage(msk_temp, out_path + '/' + str(i) +'.nii')\n",
    "\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test(data_out_dir1, 'VertSeg_train/test/out1',0)\n",
    "write_test_MR(data_out_dir2, 'VertSeg_train/test/out2',1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-2.1.0",
   "language": "python",
   "name": "tensorflow-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
